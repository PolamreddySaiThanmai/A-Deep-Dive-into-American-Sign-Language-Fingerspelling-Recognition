{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9bd3a199",
   "metadata": {
    "papermill": {
     "duration": 0.007245,
     "end_time": "2024-11-28T00:43:46.462240",
     "exception": false,
     "start_time": "2024-11-28T00:43:46.454995",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Install libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "42e7551a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-28T00:43:46.479479Z",
     "iopub.status.busy": "2024-11-28T00:43:46.478980Z",
     "iopub.status.idle": "2024-11-28T00:44:16.961653Z",
     "shell.execute_reply": "2024-11-28T00:44:16.959949Z"
    },
    "papermill": {
     "duration": 30.495018,
     "end_time": "2024-11-28T00:44:16.964825",
     "exception": false,
     "start_time": "2024-11-28T00:43:46.469807",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "try:\n",
    "  from icecream import ic\n",
    "  import pymp\n",
    "except Exception:\n",
    "  !pip install -q icecream --no-index --find-links=file:///kaggle/input/icecream\n",
    "  !pip install -q pymp-pypi --no-index --find-links=file:///kaggle/input/pymp-pypi/pymp-pypi-0.4.5/dist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8586f5bf",
   "metadata": {
    "papermill": {
     "duration": 0.007282,
     "end_time": "2024-11-28T00:44:16.979916",
     "exception": false,
     "start_time": "2024-11-28T00:44:16.972634",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Import libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "087f13cf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-28T00:44:16.997933Z",
     "iopub.status.busy": "2024-11-28T00:44:16.997398Z",
     "iopub.status.idle": "2024-11-28T00:44:31.987001Z",
     "shell.execute_reply": "2024-11-28T00:44:31.985772Z"
    },
    "papermill": {
     "duration": 15.006139,
     "end_time": "2024-11-28T00:44:31.993783",
     "exception": false,
     "start_time": "2024-11-28T00:44:16.987644",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
      "/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\n",
      "caused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl6StatusC1EN10tensorflow5error4CodeESt17basic_string_viewIcSt11char_traitsIcEENS_14SourceLocationE']\n",
      "  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n",
      "/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']\n",
      "caused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZTVN10tensorflow13GcsFileSystemE']\n",
      "  warnings.warn(f\"file system plugins are not loaded: {e}\")\n",
      "ic| tf.__version__: '2.12.0', torch.__version__: '2.0.0+cpu'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('2.12.0', '2.0.0+cpu')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys, os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import re\n",
    "import six\n",
    "import glob\n",
    "import traceback\n",
    "import inspect\n",
    "from typing import Union\n",
    "from collections import Counter, OrderedDict, defaultdict\n",
    "from collections.abc import Iterable\n",
    "from multiprocessing import cpu_count\n",
    "from tqdm.notebook import tqdm\n",
    "from icecream import ic\n",
    "import pymp\n",
    "import transformers\n",
    "import tensorflow as tf\n",
    "import torch\n",
    "from torch import nn, einsum\n",
    "import torch.nn.functional as F\n",
    "ic(tf.__version__, torch.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d41b6e82",
   "metadata": {
    "papermill": {
     "duration": 0.009262,
     "end_time": "2024-11-28T00:44:32.014359",
     "exception": false,
     "start_time": "2024-11-28T00:44:32.005097",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Flags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "de1bb70a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-28T00:44:32.036156Z",
     "iopub.status.busy": "2024-11-28T00:44:32.035389Z",
     "iopub.status.idle": "2024-11-28T00:44:32.049928Z",
     "shell.execute_reply": "2024-11-28T00:44:32.048997Z"
    },
    "papermill": {
     "duration": 0.028268,
     "end_time": "2024-11-28T00:44:32.052115",
     "exception": false,
     "start_time": "2024-11-28T00:44:32.023847",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class FLAGS(object):\n",
    "  # for tfrecords args, you could ignore\n",
    "  seed = 1024\n",
    "  batch_parse = False\n",
    "  sparse_to_dense = True\n",
    "  eval_keys = []\n",
    "  incl_keys = []\n",
    "  excl_keys = []\n",
    "  recount_tfrecords = False  \n",
    "  batch_sizes = []\n",
    "  buffer_size = 1024\n",
    "  buckets = None\n",
    "  drop_remainder = None\n",
    "  shard_by_files = True\n",
    "  shuffle_batch = None\n",
    "  shuffle_files = None\n",
    "  num_dataset_threads = 0\n",
    "  num_prefetch_batches = 1024\n",
    "  repeat_then_shuffle = False\n",
    "  length_index = 1\n",
    "  length_key = None\n",
    "  dynamic_pad = True\n",
    "  cache = False\n",
    "  cache_after_map = False\n",
    "  fixed_random = False\n",
    "  parallel_read_files = True\n",
    "  padding_idx = 0\n",
    "  dataset_keys = []\n",
    "  dataset_excl_keys = []\n",
    "  exclude_varlen_keys = False\n",
    "  prefetch = None\n",
    "  dataset_ordered = False\n",
    "    \n",
    "  torch = True\n",
    "  keras = False\n",
    "    \n",
    "  # online==False means using n-fold split and train on fold 1,2, folds-1 while valid on fold 0\n",
    "  # online==True means using all train data but still will valid on fold 0\n",
    "  online = False  \n",
    "  folds = 4\n",
    "  fold = 0\n",
    "  fold_seed = 1229\n",
    "  root = '../input/asl-fingerspelling'\n",
    "  working = '/kaggle/working'\n",
    "  use_z = True  # use x,y,z if True\n",
    "  norm_frames = True # norm frames using x - mean / std\n",
    "  concat_frames = True # concat original and normalized frames\n",
    "  add_pos = True # add abs frame pos, like 1/1000., 2/1000.\n",
    "  sup_weight = 0.1 # for supplement dataset assigin weight 0.1\n",
    "  \n",
    "  train_files = []\n",
    "  valid_files = []\n",
    "      \n",
    "  mix_sup = True # train & sup dataset\n",
    "  vie = 5 # valid interval epochs \n",
    "  lr = 2e-3\n",
    "  epochs = 400 \n",
    "  batch_size = 128\n",
    "  eval_batch_size = 256\n",
    "  awp = True\n",
    "  adv_start_epoch = None\n",
    "  adv_lr = 0.2\n",
    "  adv_eps = 0\n",
    "  fp16 = False # notice fp16 could not be set True if using awp here, otherwise nan\n",
    "  optimizer = 'Adam'\n",
    "  opt_eps = 1e-6 \n",
    "  scheduler = 'linear'\n",
    "  # for model related configs\n",
    "  encoder_layers = 17\n",
    "  encoder_units = 200 \n",
    "  n_frames = 320  \n",
    "  distributed = False\n",
    "    \n",
    "def load_json(filename):\n",
    "  with open(filename) as fh:\n",
    "    obj = json.load(fh)\n",
    "  return obj"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1327f90",
   "metadata": {
    "papermill": {
     "duration": 0.009317,
     "end_time": "2024-11-28T00:44:32.071368",
     "exception": false,
     "start_time": "2024-11-28T00:44:32.062051",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Common configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "419d6160",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-28T00:44:32.093004Z",
     "iopub.status.busy": "2024-11-28T00:44:32.092563Z",
     "iopub.status.idle": "2024-11-28T00:44:32.547944Z",
     "shell.execute_reply": "2024-11-28T00:44:32.546670Z"
    },
    "papermill": {
     "duration": 0.471136,
     "end_time": "2024-11-28T00:44:32.552363",
     "exception": false,
     "start_time": "2024-11-28T00:44:32.081227",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| len(LIP): 40\n",
      "ic| len(LLIP): 18, len(RLIP): 18, len(MID_LIP): 4\n",
      "ic| N_COLS: 384\n",
      "ic| N_CHARS: 59\n",
      "ic| PAD_IDX: 0, SOS_IDX: 0, EOS_IDX: 60\n",
      "ic| VOCAB_SIZE: 61\n",
      "ic| len(IDX2CHAR): 61\n"
     ]
    }
   ],
   "source": [
    "LPOSE = [13, 15, 17, 19, 21]\n",
    "RPOSE = [14, 16, 18, 20, 22]\n",
    "POSE = LPOSE + RPOSE\n",
    "\n",
    "LIP = [\n",
    "    61, 185, 40, 39, 37, 0, 267, 269, 270, 409,\n",
    "    291, 146, 91, 181, 84, 17, 314, 405, 321, 375,\n",
    "    78, 191, 80, 81, 82, 13, 312, 311, 310, 415,\n",
    "    95, 88, 178, 87, 14, 317, 402, 318, 324, 308,\n",
    "]\n",
    "ic(len(LIP))\n",
    "LLIP = [84,181,91,146,61,185,40,39,37,87,178,88,95,78,191,80,81,82]\n",
    "RLIP = [314,405,321,375,291,409,270,269,267,317,402,318,324,308,415,310,311,312]\n",
    "MID_LIP = [i for i in LIP if i not in LLIP + RLIP]\n",
    "ic(len(LLIP), len(RLIP), len(MID_LIP))\n",
    "\n",
    "NOSE=[\n",
    "    1,2,98,327\n",
    "]\n",
    "LNOSE = [98]\n",
    "RNOSE = [327]\n",
    "MID_NOSE = [i for i in NOSE if i not in LNOSE + RNOSE]\n",
    "\n",
    "LEYE = [\n",
    "    263, 249, 390, 373, 374, 380, 381, 382, 362,\n",
    "    466, 388, 387, 386, 385, 384, 398,\n",
    "]\n",
    "REYE = [\n",
    "    33, 7, 163, 144, 145, 153, 154, 155, 133,\n",
    "    246, 161, 160, 159, 158, 157, 173,\n",
    "]\n",
    "\n",
    "N_HAND_POINTS = 21\n",
    "N_POSE_POINTS = len(LPOSE)\n",
    "N_LIP_POINTS = len(LLIP)\n",
    "N_EYE_POINTS = len(LEYE)\n",
    "N_NOSE_POINTS = len(LNOSE)\n",
    "N_MID_POINTS = len(MID_LIP + MID_NOSE)\n",
    "\n",
    "SEL_COLS = []\n",
    "for i in range(N_HAND_POINTS):\n",
    "  SEL_COLS.extend([f'x_left_hand_{i}', f'y_left_hand_{i}', f'z_left_hand_{i}'])\n",
    "for i in range(N_HAND_POINTS):\n",
    "  SEL_COLS.extend([f'x_right_hand_{i}', f'y_right_hand_{i}', f'z_right_hand_{i}'])\n",
    "for i in LPOSE:\n",
    "  SEL_COLS.extend([f'x_pose_{i}', f'y_pose_{i}', f'z_pose_{i}'])\n",
    "for i in RPOSE:\n",
    "  SEL_COLS.extend([f'x_pose_{i}', f'y_pose_{i}', f'z_pose_{i}'])\n",
    "for i in LLIP:\n",
    "  SEL_COLS.extend([f'x_face_{i}', f'y_face_{i}', f'z_face_{i}'])\n",
    "for i in RLIP:\n",
    "  SEL_COLS.extend([f'x_face_{i}', f'y_face_{i}', f'z_face_{i}'])\n",
    "\n",
    "for i in LEYE:\n",
    "  SEL_COLS.extend([f'x_face_{i}', f'y_face_{i}', f'z_face_{i}'])\n",
    "for i in REYE:\n",
    "  SEL_COLS.extend([f'x_face_{i}', f'y_face_{i}', f'z_face_{i}'])\n",
    "  \n",
    "for i in LNOSE:\n",
    "  SEL_COLS.extend([f'x_face_{i}', f'y_face_{i}', f'z_face_{i}'])\n",
    "for i in RNOSE:\n",
    "  SEL_COLS.extend([f'x_face_{i}', f'y_face_{i}', f'z_face_{i}'])\n",
    "  \n",
    "for i in MID_LIP:\n",
    "  SEL_COLS.extend([f'x_face_{i}', f'y_face_{i}', f'z_face_{i}'])\n",
    "for i in MID_NOSE:\n",
    "  SEL_COLS.extend([f'x_face_{i}', f'y_face_{i}', f'z_face_{i}'])\n",
    "    \n",
    "N_COLS = len(SEL_COLS)\n",
    "ic(N_COLS)\n",
    "    \n",
    "CHAR2IDX = load_json(f'../input/asl-fingerspelling/character_to_prediction_index.json')\n",
    "CHAR2IDX = {k: v + 1 for k, v in CHAR2IDX.items()}\n",
    "N_CHARS = len(CHAR2IDX)\n",
    "ic(N_CHARS)\n",
    "\n",
    "PAD_IDX = 0\n",
    "SOS_IDX = PAD_IDX # Start Of Sentence\n",
    "EOS_IDX = N_CHARS + 1 # End Of Sentence\n",
    "ic(PAD_IDX, SOS_IDX, EOS_IDX)\n",
    "\n",
    "PAD_TOKEN = '<PAD>'\n",
    "SOS_TOKEN = PAD_TOKEN\n",
    "EOS_TOKEN = '<EOS>'\n",
    "\n",
    "CHAR2IDX[PAD_TOKEN] = PAD_IDX\n",
    "CHAR2IDX[EOS_TOKEN] = EOS_IDX \n",
    "\n",
    "ADDRESS_TOKEN = '<ADDRESS>'\n",
    "URL_TOKEN = '<URL>'\n",
    "PHONE_TOKEN = '<PHONE>'\n",
    "SUP_TOKEN = '<SUP>'\n",
    "\n",
    "VOCAB_SIZE = len(CHAR2IDX)\n",
    "IDX2CHAR = {v: k for k, v in CHAR2IDX.items()}\n",
    "ic(VOCAB_SIZE)\n",
    "ic(len(IDX2CHAR))\n",
    "\n",
    "STATS = {}\n",
    "CLASSES = [\n",
    "  'address', \n",
    "  'url', \n",
    "  'phone', \n",
    "  'sup',\n",
    "  ]\n",
    "PHRASE_TYPES = dict(zip(CLASSES, range(len(CLASSES))))\n",
    "N_TYPES = len(CLASSES)\n",
    "MAX_PHRASE_LEN = 32\n",
    "\n",
    "def get_vocab_size():\n",
    "  vocab_size = VOCAB_SIZE\n",
    "  return vocab_size\n",
    "\n",
    "def get_n_cols(no_motion=False, use_z=None):\n",
    "  n_cols = N_COLS\n",
    "  if use_z is None:\n",
    "    use_z = FLAGS.use_z\n",
    "  \n",
    "  if FLAGS.concat_frames:\n",
    "    assert FLAGS.norm_frames\n",
    "    n_cols += N_COLS\n",
    "  \n",
    "  if not use_z:\n",
    "    n_cols = n_cols // 3 * 2\n",
    "    \n",
    "  if FLAGS.add_pos:\n",
    "    n_cols += 1\n",
    "  \n",
    "  return n_cols"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ac0565d",
   "metadata": {
    "papermill": {
     "duration": 0.017492,
     "end_time": "2024-11-28T00:44:32.587659",
     "exception": false,
     "start_time": "2024-11-28T00:44:32.570167",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Tfrecord dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0f26aaf",
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": false,
    "execution": {
     "iopub.execute_input": "2024-11-28T00:44:32.625564Z",
     "iopub.status.busy": "2024-11-28T00:44:32.625128Z",
     "iopub.status.idle": "2024-11-28T00:44:32.660048Z",
     "shell.execute_reply": "2024-11-28T00:44:32.658832Z"
    },
    "papermill": {
     "duration": 0.057063,
     "end_time": "2024-11-28T00:44:32.662771",
     "exception": false,
     "start_time": "2024-11-28T00:44:32.605708",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def gen_inputs(files, \n",
    "           decode_fn, \n",
    "           batch_size=64,\n",
    "           post_decode_fn=None,\n",
    "           num_epochs = None, \n",
    "           num_threads=None, \n",
    "           buffer_size = 15000, #change from 1000 to 15000\n",
    "           dynamic_pad=True,\n",
    "           shuffle=True,\n",
    "           shuffle_batch=None,\n",
    "           shuffle_files=None,\n",
    "           ordered=None,\n",
    "           min_after_dequeue=None, #depreciated\n",
    "           seed=None, \n",
    "           enqueue_many=False,  #depreciated\n",
    "           fixed_random=False, \n",
    "           drop_remainder=False, \n",
    "           num_prefetch_batches=None, \n",
    "           bucket_boundaries=None,\n",
    "           length_index=None,\n",
    "           length_key=None,\n",
    "           length_fn=None,\n",
    "           bucket_batch_sizes=None,\n",
    "           repeat=True,\n",
    "           initializable=False,\n",
    "           filter_fn=None,\n",
    "           balance_pos_neg=False,\n",
    "           pos_filter_fn=None,\n",
    "           neg_filter_fn=None,\n",
    "           count_fn=None,\n",
    "           return_iterator=False,\n",
    "           Dataset=None,\n",
    "           batch_parse=False, #by default will be line parse\n",
    "           hvd_shard=True,\n",
    "           shard_by_files=False,\n",
    "           training=False,\n",
    "           simple_parse=False,\n",
    "           repeat_then_shuffle=False,\n",
    "           cache=False,\n",
    "           cache_file='',\n",
    "           cache_after_map=False,\n",
    "           device=None,\n",
    "           world_size=1,\n",
    "           rank=0,\n",
    "           parallel_read_files=False,\n",
    "           use_feed_dict=False,\n",
    "           feed_name=None,\n",
    "           padding_values=None,\n",
    "           distribute_strategy=None,\n",
    "           torch=False,\n",
    "           keras=False,\n",
    "           subset=None,\n",
    "           return_numpy=False,\n",
    "           name='input'):\n",
    "  Dataset = Dataset or tf.data.TFRecordDataset\n",
    "  AUTO = tf.data.AUTOTUNE\n",
    "  use_horovod = False\n",
    "\n",
    "  def shard(d):\n",
    "    return d.shard(hvd.size(), hvd.rank())\n",
    "\n",
    "  # Choose to use cpu outside input function like in dataset.py\n",
    "  #with tf.device('/cpu:0'):\n",
    "  if isinstance(files, str):\n",
    "    files = gezi.list_files(files)\n",
    "  assert len(files) > 0\n",
    "\n",
    "  if not num_threads:\n",
    "    num_threads = 8\n",
    "\n",
    "  if 'batch_size' in inspect.getfullargspec(decode_fn).args:\n",
    "    decode_fn_ = decode_fn\n",
    "    def decode_function(example):\n",
    "      return decode_fn_(example, batch_size)\n",
    "    decode_fn = decode_function\n",
    "    \n",
    "  if not num_epochs: \n",
    "    num_epochs = None\n",
    "\n",
    "  if shuffle:\n",
    "    if shuffle_files is None:\n",
    "      shuffle_files = True\n",
    "    if shuffle_batch is None:\n",
    "      shuffle_batch = True\n",
    "  else:\n",
    "    if shuffle_files is None:\n",
    "      shuffle_files = False\n",
    "    if shuffle_batch is None:\n",
    "      shuffle_batch = False\n",
    "    if not shuffle_files:\n",
    "      parallel_read_files = False\n",
    "\n",
    "  if fixed_random:\n",
    "    if seed is None:\n",
    "      seed = 1024\n",
    "  else:\n",
    "    pass\n",
    "\n",
    "  num_files = len(files)\n",
    "  if use_feed_dict and feed_name:\n",
    "    files = tf.compat.v1.placeholder(tf.string, [None], feed_name)\n",
    "    gezi.set_global(feed_name, files)\n",
    "\n",
    "  if not num_prefetch_batches:\n",
    "    #num_prefetch_batches = num_threads + 3\n",
    "    if buffer_size:\n",
    "      num_prefetch_batches = int(buffer_size / batch_size)\n",
    "    # else:\n",
    "    #   num_prefetch_batches = 100\n",
    "  \n",
    "  if not buffer_size and num_prefetch_batches:\n",
    "    buffer_size = num_prefetch_batches * batch_size\n",
    "    \n",
    "  options = tf.data.Options()\n",
    "  try:\n",
    "    options.threading.private_threadpool_size = num_threads\n",
    "    options.threading.max_intra_op_parallelism = 1\n",
    "  except Exception:\n",
    "    options.experimental_threading.private_threadpool_size = num_threads\n",
    "    options.experimental_threading.max_intra_op_parallelism = 1\n",
    "\n",
    "  options.experimental_distribute.auto_shard_policy = tf.data.experimental.AutoShardPolicy.DATA\n",
    "  options.experimental_deterministic = True\n",
    "\n",
    "  if shuffle and not fixed_random:\n",
    "    options.experimental_deterministic = False\n",
    "\n",
    "  if not ordered:\n",
    "    options.experimental_deterministic = False\n",
    "\n",
    "  if not parallel_read_files or num_files == 1:\n",
    "    d = Dataset(files)\n",
    "    d = d.with_options(options)\n",
    "    if use_horovod and hvd_shard:\n",
    "      d = shard(d)\n",
    "    if not use_horovod and world_size > 1:\n",
    "      d = d.shard(world_size, rank)\n",
    "  else:\n",
    "    try:\n",
    "      if shffle_files and (use_horovod or world_size > 1):\n",
    "        assert seed\n",
    "      d = tf.data.Dataset.list_files(files, shuffle=shuffle_files, seed=seed)\n",
    "      d = d.with_options(options)\n",
    "    except Exception:\n",
    "      d = tf.data.Dataset.from_tensor_slices(files)\n",
    "      d = d.with_options(options)\n",
    "    # here shard by files, not work good, especially for text line dataset with horovod\n",
    "    if use_horovod and shard_by_files:\n",
    "      d = shard(d)\n",
    "    elif world_size > 1 and shard_by_files:\n",
    "      d = d.shard(world_size, rank)\n",
    "\n",
    "    d = d.interleave(Dataset,\n",
    "                  #  cycle_length=min(len(files), 1000),  # in tf 1.14 must set and can not set as AUTOTUNE for tf 2.1 with default as AUTOTUNE\n",
    "                  block_length=1,\n",
    "                  num_parallel_calls=AUTO)\n",
    "\n",
    "    if world_size > 1 and not shard_by_files:\n",
    "      d = d.shard(world_size, rank)\n",
    "\n",
    "  if repeat and repeat_then_shuffle:\n",
    "    d = d.repeat(num_epochs)\n",
    "\n",
    "  if cache and (not FLAGS.cache_after_map):\n",
    "    d = d.cache(cache_file)\n",
    "    \n",
    "  # must batch then map if use pyfunc which you might use batch_parse, here batch_parse means batch parse otherwise slower but simple and powerfull...\n",
    "  if not batch_parse:\n",
    "    d = d.map(decode_fn, num_parallel_calls=AUTO)\n",
    "    if cache and cache_after_map:\n",
    "      d = d.cache(cache_file)\n",
    "  \n",
    "  if filter_fn is not None and not batch_parse:\n",
    "    d = d.filter(filter_fn)\n",
    "\n",
    "  if shuffle_batch:\n",
    "    d = d.shuffle(buffer_size=buffer_size, seed=seed, reshuffle_each_iteration=True)\n",
    "\n",
    "  # shuffle then repeat\n",
    "  if repeat and not repeat_then_shuffle:\n",
    "    d = d.repeat(num_epochs)\n",
    "  \n",
    "  if dynamic_pad:\n",
    "    if not batch_parse: \n",
    "      d = d.padded_batch(batch_size, drop_remainder=drop_remainder)\n",
    "    else:\n",
    "      d = d.batch(batch_size, drop_remainder=drop_remainder)\n",
    "  else:\n",
    "    d = d.batch(batch_size, drop_remainder=drop_remainder)\n",
    "\n",
    "  if batch_parse:\n",
    "    d = d.map(decode_fn, num_parallel_calls=AUTO)\n",
    "    if filter_fn is not None:\n",
    "      try:\n",
    "        d = d.unbatch()\n",
    "        d = d.filter(filter_fn)\n",
    "      except Exception:\n",
    "        d = d.unbatch()\n",
    "\n",
    "      d = d.batch(batch_size, drop_remainder=drop_remainder)\n",
    "\n",
    "  if post_decode_fn is not None:\n",
    "    d = d.map(post_decode_fn, num_parallel_calls=AUTO)\n",
    "\n",
    "  if cache and FLAGS.cache_after_map:\n",
    "    logging.debug('Cache datase after map')\n",
    "    d = d.cache(cache_file)\n",
    "\n",
    "  d = d.prefetch(FLAGS.prefetch or AUTO)\n",
    "\n",
    "  if not return_numpy:    \n",
    "    return d\n",
    "  else:\n",
    "    return d.as_numpy_iterator()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f722e25b",
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2024-11-28T00:44:32.701267Z",
     "iopub.status.busy": "2024-11-28T00:44:32.700490Z",
     "iopub.status.idle": "2024-11-28T00:44:32.721018Z",
     "shell.execute_reply": "2024-11-28T00:44:32.719880Z"
    },
    "papermill": {
     "duration": 0.042735,
     "end_time": "2024-11-28T00:44:32.723667",
     "exception": false,
     "start_time": "2024-11-28T00:44:32.680932",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def decode_example(x):\n",
    "  if tf.executing_eagerly():\n",
    "    x = x.numpy()\n",
    "  x = tf.train.Example.FromString(x).features.feature\n",
    "  features = {}\n",
    "  for key in x.keys():\n",
    "    typenames = ['bytes_list', 'float_list', 'int64_list']\n",
    "    dtypes = [object, np.float32, np.int64]\n",
    "    for typename, dtype in zip(typenames, dtypes):\n",
    "      value = getattr(x[key], typename).value\n",
    "      if value:\n",
    "        features[key] = np.array(value, dtype=dtype)\n",
    "  return features\n",
    "\n",
    "def first_example(record_file):\n",
    "  if isinstance(record_file, (list, tuple)):\n",
    "    record_file = record_file[0]\n",
    "  if tf.executing_eagerly():\n",
    "    for item in tf.data.TFRecordDataset(record_file):\n",
    "      x = decode_example(item)\n",
    "      return x\n",
    "  else:\n",
    "    for item in tf.compat.v1.python_io.tf_record_iterator(record_file):\n",
    "      x = decode_example(item)\n",
    "      return x\n",
    "\n",
    "def npdtype2tfdtype(dtype, large=False):\n",
    "  if dtype == np.float32:\n",
    "    return tf.float32\n",
    "  if dtype == np.int32:\n",
    "    if not large:\n",
    "      return tf.int32\n",
    "    else:\n",
    "      return tf.int64\n",
    "  if dtype == np.int64:\n",
    "    return tf.int64\n",
    "  if dtype == np.float64:\n",
    "    return tf.float32\n",
    "  return tf.string\n",
    "\n",
    "def sparse_tensor_to_dense(input_tensor, default_value=0):  \n",
    "  return tf.sparse.to_dense(input_tensor, default_value=default_value, validate_indices=False)\n",
    "\n",
    "def sparse2dense(features, key=None, default_value=0):\n",
    "\n",
    "  def sparse2dense_(features, key, default_value):\n",
    "    val = features[key]\n",
    "    if val.values.dtype == tf.string:\n",
    "      default_value = None\n",
    "    val = sparse_tensor_to_dense(val, default_value)\n",
    "    features[key] = val\n",
    "\n",
    "  modified = False\n",
    "  if key:\n",
    "    sparse2dense_(features, key)\n",
    "    modified = True\n",
    "  else:\n",
    "    from tensorflow.python.framework.sparse_tensor import SparseTensor\n",
    "    for key, val in features.items():\n",
    "      if isinstance(val, SparseTensor):\n",
    "        sparse2dense_(features, key, default_value)\n",
    "        modified = True\n",
    "  return modified\n",
    "\n",
    "def get_num_records_single(tf_record_file, recount=False):\n",
    "  if not recount:\n",
    "    filename = os.path.basename(tf_record_file)\n",
    "    filename = filename.replace('-', '.').replace('_', '.')\n",
    "    l = filename.split('.')\n",
    "\n",
    "    for item in reversed(l):\n",
    "      if item.isdigit():\n",
    "        return int(item)\n",
    "\n",
    "  # try:\n",
    "  return sum(\n",
    "      1 for _ in tf.compat.v1.python_io.tf_record_iterator(tf_record_file))\n",
    "  # except Exception:\n",
    "  #   return 0\n",
    "\n",
    "\n",
    "def get_num_records(files, recount=False):\n",
    "  if isinstance(files, str):\n",
    "    files = gezi.list_files(files)\n",
    "  res = sum([\n",
    "      get_num_records_single(file, recount=recount)\n",
    "      for file in tqdm(files, ascii=False, desc='get_num_records', leave=False)\n",
    "  ])\n",
    "  return res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b31280b",
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2024-11-28T00:44:32.762885Z",
     "iopub.status.busy": "2024-11-28T00:44:32.762450Z",
     "iopub.status.idle": "2024-11-28T00:44:32.836356Z",
     "shell.execute_reply": "2024-11-28T00:44:32.835309Z"
    },
    "papermill": {
     "duration": 0.096799,
     "end_time": "2024-11-28T00:44:32.839075",
     "exception": false,
     "start_time": "2024-11-28T00:44:32.742276",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# A wrapper base class for tfrecords related dataset \n",
    "class TfrecordsDataset(object):\n",
    "  def __init__(self, \n",
    "               subset='valid',\n",
    "               batch_size=None,\n",
    "               Type=None, \n",
    "               files=None,\n",
    "               num_instances=None,\n",
    "               batch_parse=None,\n",
    "               sparse_to_dense=None,\n",
    "               hvd_shard=True,\n",
    "               use_int32=True,\n",
    "               is_info=False,\n",
    "               eval_keys=[],\n",
    "               incl_keys=[],\n",
    "               excl_keys=[],\n",
    "               str_keys=[],\n",
    "               varlen_keys=[],\n",
    "               use_tpu=False,\n",
    "               recount=None):\n",
    "    self.subset = subset\n",
    "    self.filter_fn = None\n",
    "    self.pos_filter_fn = None\n",
    "    self.neg_filter_fn = None \n",
    "    self.count_fn = None\n",
    "    self.Type = Type\n",
    "    self.batch_parse = batch_parse if batch_parse is not None else FLAGS.batch_parse\n",
    "    self.sparse_to_dense = sparse_to_dense if sparse_to_dense is not None else FLAGS.sparse_to_dense\n",
    "    self.use_post_decode = None\n",
    "    # if self.batch_parse:\n",
    "    #   self.sparse_to_dense = False\n",
    "    self.batch_size = batch_size or FLAGS.batch_size\n",
    "    self.hvd_shard = hvd_shard\n",
    "    self.indexes = {'train': -1, 'valid': -1, 'test': -1}\n",
    "    self.is_info = is_info\n",
    "    self.eval_keys = eval_keys or FLAGS.eval_keys\n",
    "    if subset == 'test':\n",
    "      self.eval_keys = gezi.get('test_keys') or self.eval_keys\n",
    "    self.show_keys = set()  \n",
    "    self.excl_keys = excl_keys or FLAGS.excl_keys\n",
    "    self.incl_keys = incl_keys or FLAGS.incl_keys\n",
    "    self.str_keys = str_keys\n",
    "    self.varlen_keys = varlen_keys\n",
    "\n",
    "    self.parse_fn = tf.io.parse_single_example if not self.batch_parse else tf.io.parse_example\n",
    "\n",
    "    self.features_dict = {}\n",
    "    self.has_varlen_feats = False\n",
    "    self.use_tpu = use_tpu\n",
    "    try:\n",
    "      # TPU detection. No parameters necessary if TPU_NAME environment variable is\n",
    "      # set: this is always the case on Kaggle.\n",
    "      tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
    "      # print('Running on TPU ', tpu.master())\n",
    "    except ValueError:\n",
    "      tpu = None\n",
    "    if tpu is not None:\n",
    "      self.use_tpu = True\n",
    "    self.use_int32 = use_int32\n",
    "    if self.use_tpu:\n",
    "      self.use_int32 = True\n",
    "\n",
    "    self.num_instances_ = num_instances\n",
    "    self.files_ = files\n",
    "\n",
    "    # self.use_post_decode = use_post_decode\n",
    "    self.recount = recount or FLAGS.recount_tfrecords\n",
    "\n",
    "    assert self.subset in ['train', 'valid', 'test'], \\\n",
    "          'subset is {} but should in [train, valid, test]'.format(self.subset)\n",
    "\n",
    "  @staticmethod\n",
    "  def get_filenames_(subset=None, shuffle=False):\n",
    "    try:\n",
    "      if subset in ['train', 'valid', 'test']:\n",
    "        if subset == 'train':\n",
    "          return FLAGS.train_files\n",
    "        elif subset == 'valid':\n",
    "          return FLAGS.valid_files\n",
    "      else:\n",
    "        raise ValueError('Invalid data subset \"%s\"' % subset)\n",
    "    except Exception:\n",
    "      return None\n",
    "\n",
    "  def get_filenames(self, subset=None, shuffle=False):\n",
    "    subset = subset or self.subset\n",
    "    return TfrecordsDataset.get_filenames_(subset, shuffle=False)\n",
    "\n",
    "  def basic_parse(self, example):\n",
    "    self.auto_parse(keys=self.incl_keys, exclude_keys=self.excl_keys)\n",
    "    if self.varlen_keys:\n",
    "      self.adds_varlens(self.varlen_keys)\n",
    "    fe = self.parse_(serialized=example)\n",
    "    return fe\n",
    "  \n",
    "  # override this\n",
    "  def parse(self, example):\n",
    "    return self.basic_parse(example)\n",
    "\n",
    "  def decode(self, example):\n",
    "    l = self.parse(example)\n",
    "    \n",
    "    if isinstance(l, (list, tuple)):\n",
    "      features = l[0]\n",
    "    else:\n",
    "      features = l\n",
    "    # self.use_tpu = True\n",
    "    if isinstance(features, dict):\n",
    "      if self.use_tpu:\n",
    "        def decode_label(label):\n",
    "          label = tf.io.decode_raw(label, tf.uint8)  # tf.string -> [tf.uint8]\n",
    "          label = tf.reshape(label, [])  # label is a scalar\n",
    "          return tf.cast(label, tf.int32) \n",
    "        for key in features.keys():\n",
    "          if features[key].dtype in [tf.int64, tf.uint8, tf.uint16, tf.uint32]:\n",
    "            features[key] = tf.cast(features[key], tf.int32)\n",
    "\n",
    "        if not self.is_info:\n",
    "          keys = list(features.keys())\n",
    "          for key in keys:\n",
    "            if features[key].dtype ==tf.string:\n",
    "              del features[key]\n",
    "\n",
    "              if key in self.eval_keys:\n",
    "                FLAGS.use_info_dataset = True  \n",
    "              # features[key] = tf.ones_like(features[key], tf.int32)\n",
    "              # features[key] = decode_label(features[key]) ## not work TODO\n",
    "\n",
    "      else:\n",
    "        def _cast_dict(features):\n",
    "          for key in features:\n",
    "            if isinstance(features[key], dict):\n",
    "              _cast_dict(features[key])\n",
    "            else:\n",
    "              # tf.print(key, features[key])\n",
    "              if features[key].dtype == tf.int64 and self.use_int32:\n",
    "                features[key] = tf.cast(features[key], tf.int32)\n",
    "        _cast_dict(features)\n",
    " \n",
    "      if self.is_info:\n",
    "        keys = list(features.keys())\n",
    "        if not FLAGS.predict_on_batch:\n",
    "          if not self.eval_keys:\n",
    "            for key in keys:\n",
    "              dim = 1 if self.batch_parse else 0\n",
    "              if not (len(features[key].shape) == dim or features[key].shape[dim] == 1):\n",
    "                del features[key]\n",
    "              else:\n",
    "                self.show_keys.add(key)\n",
    "          else:\n",
    "            for key in keys:\n",
    "              if key not in self.eval_keys:\n",
    "                del features[key]\n",
    "      else:\n",
    "        keys = list(features.keys())\n",
    "        for key in keys:\n",
    "          if key in self.excl_keys:\n",
    "            del features[key]\n",
    "\n",
    "    return l\n",
    "\n",
    "  def adjust(self, result):\n",
    "    return result\n",
    "\n",
    "  def parse_(self, serialized, features=None):\n",
    "    features = features or self.features_dict\n",
    "    # ic(features)\n",
    "    features = self.parse_fn(serialized=serialized, features=features)\n",
    "    if FLAGS.exclude_varlen_keys:\n",
    "      from tensorflow.python.framework.sparse_tensor import SparseTensor\n",
    "      sparse_keys = [key for key in features if isinstance(key, SparseTensor)]\n",
    "      for key in sparse_keys:\n",
    "        del features[key]\n",
    "    else:\n",
    "      if self.sparse_to_dense:\n",
    "        modified = sparse2dense(features, default_value=FLAGS.padding_idx)\n",
    "        self.has_varlen_feats = modified\n",
    "    self.features = features\n",
    "    return features\n",
    "  \n",
    "  def gen_example(self, files=None):\n",
    "    if not files:\n",
    "      files = self.get_filenames()\n",
    "    if not isinstance(files, (list, tuple)):\n",
    "      files = [files]\n",
    "    example = {}\n",
    "    if files:\n",
    "      for file in files:\n",
    "        try:\n",
    "          example = first_example(file)\n",
    "        except Exception:\n",
    "          ic(traceback.format_exc())\n",
    "          ic('bad tfrecord:', file)\n",
    "        if example:\n",
    "          self.example = example\n",
    "          break\n",
    "    self.example = example\n",
    "    return example\n",
    "\n",
    "  def gen_input(self, files=None):\n",
    "    example = self.gen_example().copy()\n",
    "    for key in example:\n",
    "      example[key] = np.asarray([example[key]])\n",
    "    return example\n",
    "\n",
    "  def first_input(self, files=None):\n",
    "    return self.gen_input(files)\n",
    "\n",
    "  def add(self, key, dtype=None, length=None, features_dict=None):\n",
    "    features_dict = features_dict or self.features_dict\n",
    "    dtype_ = dtype\n",
    "    if key in self.example:\n",
    "      dtype = dtype_ or self.example[key].dtype \n",
    "      if length is None:\n",
    "        features_dict[key] = tf.io.VarLenFeature(dtype)\n",
    "      elif length > 0:\n",
    "        features_dict[key] = tf.io.FixedLenFeature([length], dtype)\n",
    "      else:\n",
    "        features_dict[key] = tf.io.FixedLenFeature([], dtype)\n",
    "    \n",
    "  def adds(self, keys, dtype=None, length=None, features_dict=None):\n",
    "    features_dict = features_dict or self.features_dict\n",
    "    dtype_ = dtype\n",
    "    for key in keys:\n",
    "      if key in self.example:\n",
    "        dtype = dtype_ or self.example[key].dtype \n",
    "        if length is None:\n",
    "          features_dict[key] = tf.io.VarLenFeature(dtype)\n",
    "        elif length > 0:\n",
    "          features_dict[key] = tf.io.FixedLenFeature([length], dtype)\n",
    "        else:\n",
    "          features_dict[key] = tf.io.FixedLenFeature([], dtype)\n",
    "\n",
    "  def auto_parse(self, keys=[], exclude_keys=[], features_dict=None):\n",
    "    keys = keys or FLAGS.dataset_keys or self.example.keys()\n",
    "    exclude_keys = exclude_keys or FLAGS.dataset_excl_keys\n",
    "    keys = [key for key in keys if key not in exclude_keys]\n",
    "\n",
    "    for key in keys:\n",
    "      if key not in self.example:\n",
    "        continue\n",
    "      length = self.example[key].shape[0]\n",
    "      \n",
    "      if length == 1:\n",
    "        # just to (bs,), tf keras will auto change to (bs,1), also for string 0 is ok\n",
    "        length = 0 \n",
    "\n",
    "      dtype = npdtype2tfdtype(self.example[key].dtype)\n",
    "      # print(key, dtype, length, self.example[key])\n",
    "      self.adds([key], dtype, length, features_dict)\n",
    "\n",
    "  def adds_varlens(self, keys=[], exclude_keys=[], features_dict=None):\n",
    "    keys = keys or self.example.keys()\n",
    "    keys = [key for key in keys if key not in exclude_keys]\n",
    "\n",
    "    for key in keys:\n",
    "      if not key in self.example:\n",
    "        continue\n",
    "      length = self.example[key].shape[0]\n",
    "      dtype = npdtype2tfdtype(self.example[key].dtype)\n",
    "      length = None\n",
    "      if dtype == tf.string:\n",
    "        length = 1\n",
    "      self.adds([key], dtype, length, features_dict)  \n",
    "  \n",
    "  def make_batch(self, \n",
    "                 batch_size=None, \n",
    "                 filenames=None,\n",
    "                 subset=None,\n",
    "                 initializable=False,\n",
    "                 repeat=None,\n",
    "                 shuffle=None,\n",
    "                 return_iterator=True,\n",
    "                 hvd_shard=None,\n",
    "                 simple_parse=False,\n",
    "                 num_epochs=None,\n",
    "                 cache=False,\n",
    "                 cache_file='',\n",
    "                 buffer_size=None,\n",
    "                 batch_sizes=None,\n",
    "                 buckets=None,\n",
    "                 drop_remainder=None,\n",
    "                 world_size=1,\n",
    "                 rank=0,\n",
    "                 shard_by_files=None,\n",
    "                 distribute_strategy=None,\n",
    "                 return_numpy=False):\n",
    "    # with tf.device('/cpu:0'):\n",
    "    subset = subset or self.subset\n",
    "    hvd_shard = hvd_shard if hvd_shard is not None else self.hvd_shard\n",
    "    if batch_size is None:\n",
    "      is_test = True\n",
    "    else:\n",
    "      is_test = False\n",
    "    batch_size = batch_size or self.batch_size\n",
    "    self.batch_size = batch_size\n",
    "    batch_sizes = batch_sizes if batch_sizes is not None else FLAGS.batch_sizes\n",
    "    buffer_size = buffer_size if buffer_size is not None else FLAGS.buffer_size\n",
    "    buckets = buckets if buckets is not None else FLAGS.buckets\n",
    "    drop_remainder = drop_remainder if drop_remainder is not None else FLAGS.drop_remainder\n",
    "    shard_by_files = shard_by_files if shard_by_files is not None else FLAGS.shard_by_files\n",
    "\n",
    "    self.return_numpy = return_numpy\n",
    "\n",
    "    filenames = filenames or self.files_ or self.get_filenames(subset)\n",
    "    \n",
    "    self.gen_example(filenames)\n",
    "\n",
    "    is_eager = tf.executing_eagerly()\n",
    "\n",
    "    self.files_ = filenames\n",
    "\n",
    "    self.indexes[self.subset] += 1\n",
    "    \n",
    "    if repeat is None:\n",
    "      num_gpus = 1\n",
    "      # if subset == 'train' or num_gpus > 1:\n",
    "      if subset == 'train':\n",
    "        repeat = True\n",
    "      else:\n",
    "        repeat = False\n",
    "      if is_eager and num_gpus == 1 and tf.__version__ < '2':\n",
    "        # let tf eager similary to pytorch\n",
    "        repeat = False\n",
    "\n",
    "    if shuffle is None:\n",
    "      if subset == 'train':\n",
    "        shuffle = FLAGS.shuffle \n",
    "      else:\n",
    "        shuffle = FLAGS.shuffle_valid \n",
    "\n",
    "    if drop_remainder is None:\n",
    "      if subset == 'train':\n",
    "        drop_remainder = True\n",
    "      else:\n",
    "        drop_remainder = False\n",
    "\n",
    "    balance_pos_neg=False\n",
    "    ic(self.subset, repeat, drop_remainder)\n",
    "\n",
    "    seed = FLAGS.seed \n",
    "    if seed is not None:\n",
    "      FLAGS.seed += 1\n",
    "\n",
    "    ## put on cpu or dummy\n",
    "    with tf.device('/cpu'):\n",
    "      result = gen_inputs(\n",
    "        filenames, \n",
    "        decode_fn=self.decode,\n",
    "        batch_size=batch_size,\n",
    "        post_decode_fn=self.post_decode if hasattr(self, 'post_decode') and self.use_post_decode != False else None,\n",
    "        shuffle=shuffle,\n",
    "        shuffle_batch=FLAGS.shuffle_batch,\n",
    "        shuffle_files=FLAGS.shuffle_files,\n",
    "        ordered=FLAGS.dataset_ordered if subset == 'train' else True,\n",
    "        num_threads=FLAGS.num_dataset_threads,\n",
    "        buffer_size=buffer_size,\n",
    "        num_prefetch_batches=FLAGS.num_prefetch_batches,\n",
    "        initializable=initializable,\n",
    "        repeat=repeat,\n",
    "        repeat_then_shuffle=FLAGS.repeat_then_shuffle,\n",
    "        drop_remainder=drop_remainder,\n",
    "        bucket_boundaries=buckets,\n",
    "        bucket_batch_sizes=batch_sizes,\n",
    "        length_index=FLAGS.length_index,\n",
    "        length_key=FLAGS.length_key,\n",
    "        seed=seed,\n",
    "        return_iterator=return_iterator,\n",
    "        filter_fn=self.filter_fn,  # inside filter_fn judge subset train or valid or test\n",
    "        balance_pos_neg=balance_pos_neg,\n",
    "        pos_filter_fn=self.pos_filter_fn if subset == 'train' else None,\n",
    "        neg_filter_fn=self.neg_filter_fn if subset == 'train' else None,\n",
    "        count_fn=self.count_fn if subset == 'train' else None,\n",
    "        name=subset,\n",
    "        Dataset=self.Type,\n",
    "        batch_parse=self.batch_parse,\n",
    "        hvd_shard=hvd_shard,\n",
    "        shard_by_files=shard_by_files,\n",
    "        training=subset == 'train',\n",
    "        simple_parse=simple_parse,\n",
    "        num_epochs=num_epochs,\n",
    "        dynamic_pad=FLAGS.dynamic_pad,\n",
    "        cache=cache,\n",
    "        cache_file=cache_file,\n",
    "        cache_after_map=FLAGS.cache_after_map,\n",
    "        device='/gpu:0',\n",
    "        world_size=world_size,\n",
    "        rank=rank,\n",
    "        fixed_random=FLAGS.fixed_random,\n",
    "        parallel_read_files=FLAGS.parallel_read_files,\n",
    "        #use_feed_dict=FLAGS.train_loop and FLAGS.rounds > 1 and not is_eager and FLAGS.feed_dataset and tf.__version__ < '2',\n",
    "        feed_name=f'{self.subset}_{self.indexes[self.subset]}' if not is_test else None,\n",
    "        padding_values=FLAGS.padding_idx, \n",
    "        distribute_strategy=distribute_strategy,\n",
    "        torch=FLAGS.torch,\n",
    "        keras=FLAGS.keras,\n",
    "        subset=self.subset,\n",
    "        return_numpy=return_numpy,\n",
    "        ) \n",
    "      \n",
    "    result = self.adjust(result)\n",
    "    return result\n",
    "    \n",
    "  @staticmethod\n",
    "  def num_examples_per_epoch(subset, dir=None):\n",
    "    if subset == 'train':\n",
    "      num_examples = get_num_records(FLAGS.train_files)\n",
    "    elif subset == 'valid':\n",
    "      num_examples = get_num_records(FLAGS.valid_files)\n",
    "    else:\n",
    "      raise ValueError('Invalid data subset \"%s\"' % subset)\n",
    "    \n",
    "    assert num_examples\n",
    "    return num_examples\n",
    "\n",
    "  @staticmethod\n",
    "  def num_examples(subset, dir=None):\n",
    "    return Dataset.num_examples_per_epoch(subset, dir)\n",
    "\n",
    "  @property\n",
    "  def num_instances(self):\n",
    "    if self.num_instances_:\n",
    "      return self.num_instances_\n",
    "    assert self.files_\n",
    "    self.num_instances_ = get_num_records(self.files_, recount=self.recount)\n",
    "    return self.num_instances_\n",
    "\n",
    "  @property\n",
    "  def files(self):\n",
    "    return self.files_\n",
    "\n",
    "  @property\n",
    "  def records(self):\n",
    "    return self.files_\n",
    "\n",
    "  def __len__(self):\n",
    "    return self.num_instances or Dataset.num_examples_per_epoch(self.subset)\n",
    "\n",
    "  @property\n",
    "  def num_steps(self):\n",
    "    return -(-len(self) // self.batch_size)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35618551",
   "metadata": {
    "papermill": {
     "duration": 0.018584,
     "end_time": "2024-11-28T00:44:32.875728",
     "exception": false,
     "start_time": "2024-11-28T00:44:32.857144",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Generate means.npy and stds.npy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "10cd672d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-28T00:44:32.913863Z",
     "iopub.status.busy": "2024-11-28T00:44:32.913110Z",
     "iopub.status.idle": "2024-11-28T00:44:36.348130Z",
     "shell.execute_reply": "2024-11-28T00:44:36.346982Z"
    },
    "papermill": {
     "duration": 3.459295,
     "end_time": "2024-11-28T00:44:36.352878",
     "exception": false,
     "start_time": "2024-11-28T00:44:32.893583",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| record_files[:2]: ['../input/3rd-place-step1-gen-tfrecords-for-train/tfrecords/train/20.232.tfrec',\n",
      "                       '../input/3rd-place-step1-gen-tfrecords-for-train/tfrecords/train/209.266.tfrec']\n",
      "ic| self.subset: 'valid', repeat: False, drop_remainder: False\n",
      "ic| dataset.features_dict: {'frames': VarLenFeature(dtype=tf.float32),\n",
      "                            'n_frames': FixedLenFeature(shape=[], dtype=tf.int64, default_value=None)}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9eca95996e54f4fbc93910813158a37",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "get_num_records:   0%|          | 0/272 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| dataset.num_instances: 67208\n",
      "ic| num_steps: 66\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "66"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "records_pattern = f'../input/3rd-place-step1-gen-tfrecords-for-train/tfrecords/train/*.tfrec'\n",
    "record_files = glob.glob(records_pattern)\n",
    "ic(record_files[:2])\n",
    "dataset = TfrecordsDataset('valid', \n",
    "                      files=record_files, \n",
    "                      incl_keys=['frames', 'n_frames'],\n",
    "                      varlen_keys=['frames'],\n",
    "                          )\n",
    "datas = dataset.make_batch(1024, \n",
    "                           shuffle=False, \n",
    "                           drop_remainder=False, \n",
    "                           return_numpy=True)\n",
    "ic(dataset.features_dict)\n",
    "ic(dataset.num_instances)\n",
    "num_steps = dataset.num_steps\n",
    "ic(num_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "62061b74",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-28T00:44:36.420768Z",
     "iopub.status.busy": "2024-11-28T00:44:36.420273Z",
     "iopub.status.idle": "2024-11-28T00:44:36.432273Z",
     "shell.execute_reply": "2024-11-28T00:44:36.431102Z"
    },
    "papermill": {
     "duration": 0.044282,
     "end_time": "2024-11-28T00:44:36.434484",
     "exception": false,
     "start_time": "2024-11-28T00:44:36.390202",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/5543651/computing-standard-deviation-in-a-stream\n",
    "class OnlineVariance(object):\n",
    "    \"\"\"\n",
    "    Welford's algorithm computes the sample variance incrementally.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, iterable=None, ddof=1):\n",
    "        self.ddof, self.n, self.mean_, self.M2 = ddof, 0, 0.0, 0.0\n",
    "        if iterable is not None:\n",
    "            for datum in iterable:\n",
    "                self.include(datum)\n",
    "\n",
    "    def add(self, datum):\n",
    "        self.n += 1\n",
    "        self.delta = datum - self.mean\n",
    "        self.mean_ += self.delta / self.n\n",
    "        self.M2 += self.delta * (datum - self.mean_)\n",
    "\n",
    "    @property\n",
    "    def variance(self):\n",
    "        return self.M2 / (self.n - self.ddof)\n",
    "\n",
    "    @property\n",
    "    def std(self):\n",
    "        return np.sqrt(self.variance)\n",
    "    \n",
    "    @property\n",
    "    def mean(self):\n",
    "      return self.mean_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f343ffbc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-28T00:44:36.493584Z",
     "iopub.status.busy": "2024-11-28T00:44:36.493198Z",
     "iopub.status.idle": "2024-11-28T00:48:45.821802Z",
     "shell.execute_reply": "2024-11-28T00:48:45.817853Z"
    },
    "papermill": {
     "duration": 249.362961,
     "end_time": "2024-11-28T00:48:45.825783",
     "exception": false,
     "start_time": "2024-11-28T00:44:36.462822",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| N_COLS: 384\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d62fe53e9c94c1eb2bcf69eb64b422e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loop-dataset:   0%|          | 0/66 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ic(N_COLS)\n",
    "means = np.zeros([N_COLS], dtype=np.float32)\n",
    "stds = np.zeros([N_COLS], dtype=np.float32)\n",
    "ovs = [OnlineVariance() for _ in range(N_COLS)]\n",
    "# using streaming mean due to memory limit, notice since the last batch size might not be 1024, so maybe a bit different from all in cache mean results, however should not diff much\n",
    "for x in tqdm(datas, total=num_steps, desc='Loop-dataset'):\n",
    "  batch_frames = x['frames']\n",
    "  batch_n_frames = x['n_frames']\n",
    "  batch_frames = batch_frames.reshape(batch_frames.shape[0], -1, N_COLS)\n",
    "  l = []\n",
    "  for frames, n_frames in zip(batch_frames, batch_n_frames):\n",
    "    frames = frames[:n_frames]\n",
    "    l.append(frames)\n",
    "  frames = np.concatenate(l)\n",
    "  for col, v in enumerate(frames.reshape([-1, N_COLS]).T):\n",
    "    v = v[~np.isnan(v)]\n",
    "    ovs[col].add(v.astype(np.float32).mean())\n",
    "        \n",
    "for i, ov in enumerate(ovs):\n",
    "  means[i] = ov.mean\n",
    "  # very important, other wise keras and tflite results diff...\n",
    "  if ov.std >= 1e-6:\n",
    "    stds[i] = ov.std\n",
    "  else:\n",
    "    stds[i] = 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6a977aae",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-28T00:48:45.889386Z",
     "iopub.status.busy": "2024-11-28T00:48:45.888869Z",
     "iopub.status.idle": "2024-11-28T00:48:45.897479Z",
     "shell.execute_reply": "2024-11-28T00:48:45.896317Z"
    },
    "papermill": {
     "duration": 0.043467,
     "end_time": "2024-11-28T00:48:45.900195",
     "exception": false,
     "start_time": "2024-11-28T00:48:45.856728",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "np.save(f'{FLAGS.working}/means.npy', means)\n",
    "np.save(f'{FLAGS.working}/stds.npy', stds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea6b0b7f",
   "metadata": {
    "papermill": {
     "duration": 0.029826,
     "end_time": "2024-11-28T00:48:45.959966",
     "exception": false,
     "start_time": "2024-11-28T00:48:45.930140",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 313.37306,
   "end_time": "2024-11-28T00:48:48.716099",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-11-28T00:43:35.343039",
   "version": "2.4.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "076928dd77194d3cab463f402cc6946e": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "0d62fe53e9c94c1eb2bcf69eb64b422e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_63f271adf3b6434daf2a3c4879941551",
        "IPY_MODEL_7b9780e9616b477888caf23c91712f1d",
        "IPY_MODEL_2f7bd30dd6d540568b15ea8aae7819fb"
       ],
       "layout": "IPY_MODEL_58f31fedefc3440280f25d646294f400"
      }
     },
     "0edc9e9d762e46dc8de3c6d4fb73fdb4": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": "hidden",
       "width": null
      }
     },
     "18aed977eed94d9f9a3a6fd0645bcf11": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_076928dd77194d3cab463f402cc6946e",
       "max": 272,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_8f9e7641fb314583872bcaf5f7e331f5",
       "value": 272
      }
     },
     "2f7bd30dd6d540568b15ea8aae7819fb": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_fb1d62ab9bbb4bcc89820d637226d82d",
       "placeholder": "",
       "style": "IPY_MODEL_96e5ff7cacf6414bb408f57be57af01b",
       "value": " 66/66 [04:09&lt;00:00,  3.13s/it]"
      }
     },
     "40a9ac2cce064716b234263e2c65445d": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "46457a0c05ef4a938c116833bf6da8a2": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "58f31fedefc3440280f25d646294f400": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "63f271adf3b6434daf2a3c4879941551": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_b92a773e036d4df79d48905594fbe9e3",
       "placeholder": "",
       "style": "IPY_MODEL_d32b284f648940e69279e5f8400a9626",
       "value": "Loop-dataset: 100%"
      }
     },
     "7b9780e9616b477888caf23c91712f1d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_9dd6a9dd9f2143ac93c58f758f0a7475",
       "max": 66,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_99f12777b3764c6a82ed87a7879f6fa6",
       "value": 66
      }
     },
     "8f9e7641fb314583872bcaf5f7e331f5": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "96e5ff7cacf6414bb408f57be57af01b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "99f12777b3764c6a82ed87a7879f6fa6": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "9dd6a9dd9f2143ac93c58f758f0a7475": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "b398244ce6044274b366022b9347f5e1": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_40a9ac2cce064716b234263e2c65445d",
       "placeholder": "",
       "style": "IPY_MODEL_ea47e667d830424cbc921d4ad6dd8ce5",
       "value": "get_num_records:   0%"
      }
     },
     "b92a773e036d4df79d48905594fbe9e3": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "c9eca95996e54f4fbc93910813158a37": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_b398244ce6044274b366022b9347f5e1",
        "IPY_MODEL_18aed977eed94d9f9a3a6fd0645bcf11",
        "IPY_MODEL_d41255d422cc4642bfff1c434e293fd7"
       ],
       "layout": "IPY_MODEL_0edc9e9d762e46dc8de3c6d4fb73fdb4"
      }
     },
     "d32b284f648940e69279e5f8400a9626": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "d41255d422cc4642bfff1c434e293fd7": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_d4a97b0495344ef1b52d44129869fbd1",
       "placeholder": "",
       "style": "IPY_MODEL_46457a0c05ef4a938c116833bf6da8a2",
       "value": " 0/272 [00:00&lt;?, ?it/s]"
      }
     },
     "d4a97b0495344ef1b52d44129869fbd1": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "ea47e667d830424cbc921d4ad6dd8ce5": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "fb1d62ab9bbb4bcc89820d637226d82d": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
